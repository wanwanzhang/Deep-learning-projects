{
    "nbformat_minor": 1, 
    "metadata": {
        "language_info": {
            "nbconvert_exporter": "python", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "pygments_lexer": "ipython3", 
            "name": "python", 
            "file_extension": ".py", 
            "version": "3.5.2", 
            "mimetype": "text/x-python"
        }, 
        "kernelspec": {
            "language": "python", 
            "name": "python3-spark20", 
            "display_name": "Python 3.5 (Experimental) with Spark 2.0"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "execution_count": 1, 
            "metadata": {}, 
            "source": "from __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nimport os\nimport pickle\nimport numpy as np", 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 2, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "from keras.layers import AveragePooling2D", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 3, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "num_predictions = 20\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'keras_cifar10_trained_model.h5'", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 4, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The data, shuffled and split between train and test sets:\n(x_train, y_train), (x_test, y_test)= cifar10.load_data()", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 5, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "x_train = np.concatenate((x_train,x_test), axis=0)\ny_train = np.concatenate((y_train,y_test), axis=0)", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 6, 
            "metadata": {}, 
            "source": "seed = 3\nnp.random.seed(seed)\na = np.random.randint(60000,size=12000)\nx_train = x_train[a]\ny_train = y_train[a]\nx_train.shape\ny_train.shape", 
            "outputs": [
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(12000, 1)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 7, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "num_classes = 10", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 8, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 9, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "model = Sequential()", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 10, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "model.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 11, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "model.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 12, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "model.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 13, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "### using SGD as optimizer \nopt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 14, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Let's train the model using SGD\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 15, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 16, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 17, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 18, 
            "metadata": {}, 
            "source": "    history = model.fit_generator(datagen.flow(x_train, y_train,\n                                     batch_size=32),\n                        steps_per_epoch=x_train.shape[0] // 32,\n                        epochs=5,\n                        validation_data=(x_test, y_test),\n                        workers=4)", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Epoch 1/5\n375/375 [==============================] - 21s - loss: 2.1314 - acc: 0.2037 - val_loss: 1.9262 - val_acc: 0.2779\nEpoch 2/5\n375/375 [==============================] - 20s - loss: 1.9235 - acc: 0.2993 - val_loss: 1.7331 - val_acc: 0.3745\nEpoch 3/5\n375/375 [==============================] - 20s - loss: 1.7841 - acc: 0.3472 - val_loss: 1.5999 - val_acc: 0.4269\nEpoch 4/5\n375/375 [==============================] - 20s - loss: 1.6700 - acc: 0.3800 - val_loss: 1.4962 - val_acc: 0.4493\nEpoch 5/5\n375/375 [==============================] - 20s - loss: 1.5723 - acc: 0.4216 - val_loss: 1.4353 - val_acc: 0.4797\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 19, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "score = model.evaluate(x_test, y_test, verbose=0)", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 20, 
            "metadata": {}, 
            "source": "score", 
            "outputs": [
                {
                    "execution_count": 20, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[1.4353483554840087, 0.47970000000000002]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 21, 
            "metadata": {}, 
            "source": "# Save model and weights\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Saved trained model at %s ' % model_path)", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Saved trained model at /gpfs/global_fs01/sym_shared/YPProdSpark/user/s45f-65f67acefe15fa-238764f4c881/notebook/work/saved_models/keras_cifar10_trained_model.h5 \n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 22, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "\n# Load label names to use in prediction results\nlabel_list_path = 'datasets/cifar-10-batches-py/batches.meta'", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 23, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "keras_dir = os.path.expanduser(os.path.join('~', '.keras'))\ndatadir_base = os.path.expanduser(keras_dir)\nif not os.access(datadir_base, os.W_OK):\n    datadir_base = os.path.join('/tmp', '.keras')\nlabel_list_path = os.path.join(datadir_base, label_list_path)\n\nwith open(label_list_path, mode='rb') as f:\n    labels = pickle.load(f)", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 25, 
            "metadata": {}, 
            "source": "\npredict_gen = model.predict_generator(datagen.flow(x_test, y_test,\n                                                   batch_size=32,\n                                                   shuffle=False),\n                                      steps=x_test.shape[0] // 32,\n                                      workers=4)", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 26, 
            "metadata": {}, 
            "source": "i=0\nfor predict_index, predicted_y in enumerate(predict_gen):\n    actual_label = labels['label_names'][np.argmax(y_test[predict_index])]\n    predicted_label = labels['label_names'][np.argmax(predicted_y)]\n    print('Actual Label = %s vs. Predicted Label = %s' % (actual_label,\n                                                          predicted_label))\n    if actual_label == predicted_label: print(i)\n    if predict_index == num_predictions:\n        break\n        i", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Actual Label = cat vs. Predicted Label = deer\nActual Label = ship vs. Predicted Label = deer\nActual Label = ship vs. Predicted Label = horse\nActual Label = airplane vs. Predicted Label = cat\nActual Label = frog vs. Predicted Label = deer\nActual Label = frog vs. Predicted Label = ship\nActual Label = automobile vs. Predicted Label = truck\nActual Label = frog vs. Predicted Label = cat\nActual Label = cat vs. Predicted Label = truck\nActual Label = automobile vs. Predicted Label = frog\nActual Label = airplane vs. Predicted Label = dog\nActual Label = truck vs. Predicted Label = deer\nActual Label = dog vs. Predicted Label = ship\nActual Label = horse vs. Predicted Label = ship\nActual Label = truck vs. Predicted Label = frog\nActual Label = ship vs. Predicted Label = truck\nActual Label = dog vs. Predicted Label = deer\nActual Label = horse vs. Predicted Label = deer\nActual Label = ship vs. Predicted Label = truck\nActual Label = frog vs. Predicted Label = ship\nActual Label = horse vs. Predicted Label = frog\n"
                }
            ], 
            "cell_type": "code"
        }
    ]
}