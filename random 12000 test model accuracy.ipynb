{
    "metadata": {
        "language_info": {
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "file_extension": ".py", 
            "version": "3.5.2"
        }, 
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 2.0", 
            "name": "python3-spark20", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "source": "from __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nimport os\nimport pickle\nimport numpy as np", 
            "metadata": {}, 
            "execution_count": 7, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n"
                }
            ]
        }, 
        {
            "source": "from keras.layers import AveragePooling2D", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 8, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "num_predictions = 20\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'keras_cifar10_trained_model.h5'", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 65, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# The data, shuffled and split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')", 
            "metadata": {}, 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "x_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\n"
                }
            ]
        }, 
        {
            "source": "y_train.shape", 
            "metadata": {}, 
            "execution_count": 79, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "(50000, 10)"
                    }, 
                    "metadata": {}, 
                    "execution_count": 79, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "num_classes = 10", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 10, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 11, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model = Sequential()", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 12, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 13, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 14, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 15, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "### using SGD as optimizer \nopt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 16, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# initiate RMSprop optimizer\nopt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Let's train the model using SGD\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 18, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 19, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 20, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 21, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "    history = model.fit_generator(datagen.flow(x_train, y_train,\n                                     batch_size=32),\n                        steps_per_epoch=x_train.shape[0] // 32,\n                        epochs=5,\n                        validation_data=(x_test, y_test),\n                        workers=4)", 
            "metadata": {}, 
            "execution_count": 22, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Epoch 1/5\n1562/1562 [==============================] - 103s - loss: 1.8781 - acc: 0.3075 - val_loss: 1.5112 - val_acc: 0.4358\nEpoch 2/5\n1562/1562 [==============================] - 102s - loss: 1.5178 - acc: 0.4423 - val_loss: 1.2816 - val_acc: 0.5348\nEpoch 3/5\n1562/1562 [==============================] - 102s - loss: 1.3717 - acc: 0.5030 - val_loss: 1.2000 - val_acc: 0.5744\nEpoch 4/5\n1562/1562 [==============================] - 101s - loss: 1.2512 - acc: 0.5509 - val_loss: 1.0514 - val_acc: 0.6236\nEpoch 5/5\n1562/1562 [==============================] - 101s - loss: 1.1590 - acc: 0.5863 - val_loss: 0.9896 - val_acc: 0.6435\n"
                }
            ]
        }, 
        {
            "source": "score = model.evaluate(x_test, y_test, verbose=0)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 24, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "score", 
            "metadata": {}, 
            "execution_count": 25, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "[0.98959917469024661, 0.64349999999999996]"
                    }, 
                    "metadata": {}, 
                    "execution_count": 25, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "# Save model and weights\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Saved trained model at %s ' % model_path)", 
            "metadata": {}, 
            "execution_count": 66, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Saved trained model at /gpfs/global_fs01/sym_shared/YPProdSpark/user/s45f-65f67acefe15fa-238764f4c881/notebook/work/saved_models/keras_cifar10_trained_model.h5 \n"
                }
            ]
        }, 
        {
            "source": "\n# Load label names to use in prediction results\nlabel_list_path = 'datasets/cifar-10-batches-py/batches.meta'", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 67, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "keras_dir = os.path.expanduser(os.path.join('~', '.keras'))\ndatadir_base = os.path.expanduser(keras_dir)\nif not os.access(datadir_base, os.W_OK):\n    datadir_base = os.path.join('/tmp', '.keras')\nlabel_list_path = os.path.join(datadir_base, label_list_path)\n\nwith open(label_list_path, mode='rb') as f:\n    labels = pickle.load(f)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 68, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "from random import *", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 26, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "(sampleTrain_x,sampleTrain_y),(sampleTest_x,sampleTest_y) = cifar10.load_data()", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 52, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "sampleTrain_x = np.concatenate((sampleTrain_x,sampleTest_x), axis=0)\nsampleTrain_y = np.concatenate((sampleTrain_y,sampleTest_y), axis=0)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 53, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "seed = 3\nnp.random.seed(seed)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 54, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "a = np.random.randint(60000,size=12000)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 55, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "a", 
            "metadata": {}, 
            "execution_count": 56, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([ 5994,  1688, 11513, ..., 44318, 49235, 25563])"
                    }, 
                    "metadata": {}, 
                    "execution_count": 56, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "sampleTrain_x = sampleTrain_x[a]\nsampleTrain_y = sampleTrain_y[a]", 
            "metadata": {}, 
            "execution_count": 57, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "sampleTrain_x.shape", 
            "metadata": {}, 
            "execution_count": 61, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "(12000, 32, 32, 3)"
                    }, 
                    "metadata": {}, 
                    "execution_count": 61, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "sampleTrain_y.shape", 
            "metadata": {}, 
            "execution_count": 62, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "(12000, 1)"
                    }, 
                    "metadata": {}, 
                    "execution_count": 62, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "\npredict_gen = model.predict_generator(datagen.flow(sampleTrain_x, sampleTrain_y,\n                                                   batch_size=32,\n                                                   shuffle=False),\n                                      steps=x_test.shape[0] // 32,\n                                      workers=4)", 
            "metadata": {}, 
            "execution_count": 63, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "i=0\nfor predict_index, predicted_y in enumerate(predict_gen):\n    actual_label = labels['label_names'][np.argmax(sampleTrain_y[predict_index])]\n    predicted_label = labels['label_names'][np.argmax(predicted_y)]\n    print('Actual Label = %s vs. Predicted Label = %s' % (actual_label,\n                                                          predicted_label))\n    if actual_label == predicted_label: print(i)\n    if predict_index == num_predictions:\n        break\n        i", 
            "metadata": {}, 
            "execution_count": 82, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Actual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = horse\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = horse\nActual Label = airplane vs. Predicted Label = ship\nActual Label = airplane vs. Predicted Label = bird\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = airplane\n0\nActual Label = airplane vs. Predicted Label = horse\n"
                }
            ]
        }, 
        {
            "source": "### retrain model using these 12000 images \nsampleTrain_x\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model = Sequential()", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "### using SGD as optimizer \nopt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Let's train the model using SGD\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}