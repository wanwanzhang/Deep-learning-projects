{
    "metadata": {
        "language_info": {
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 3
            }, 
            "file_extension": ".py", 
            "version": "3.5.2"
        }, 
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 2.0", 
            "name": "python3-spark20", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "source": "from __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nimport os\nimport pickle\nimport numpy as np", 
            "metadata": {}, 
            "execution_count": 1, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n"
                }
            ]
        }, 
        {
            "source": "from keras.layers import AveragePooling2D", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 7, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# The data, shuffled and split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')", 
            "metadata": {}, 
            "execution_count": 2, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "x_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\n"
                }
            ]
        }, 
        {
            "source": "num_classes = 10", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 3, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 4, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model = Sequential()", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))", 
            "metadata": {}, 
            "execution_count": 8, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "model.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 10, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "### using SGD as optimizer \nopt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 11, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# initiate RMSprop optimizer\nopt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Let's train the model using RMSprop\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 12, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 13, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 14, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 15, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "    model.fit_generator(datagen.flow(x_train, y_train,\n                                     batch_size=32),\n                        steps_per_epoch=x_train.shape[0] // 10,\n                        epochs=5,\n                        validation_data=(x_test, y_test),\n                        workers=4)", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Epoch 1/5\n3060/5000 [=================>............] - ETA: 129s - loss: 1.6739 - acc: 0.3807"
                }
            ]
        }, 
        {
            "source": "# Evaluate model with test data set and share sample prediction results\nevaluation = model.evaluate_generator(datagen.flow(x_test, y_test,\n                                                   batch_size=batch_size,\n                                                   shuffle=False),\n                                      steps=x_test.shape[0] // batch_size,\n                                      workers=4)\nprint('Model Accuracy = %.2f' % (evaluation[1]))", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 1
}